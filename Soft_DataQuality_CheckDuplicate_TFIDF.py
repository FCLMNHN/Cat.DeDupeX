import pandas as pd
import re
import csv
import os
import sys
import unicodedata 
from fuzzywuzzy import fuzz
from typing import List, Tuple, Dict, Any, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed
import requests 
import io 
from datetime import datetime 
from pathlib import Path 

# NOUVEAUX IMPORTS POUR TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Importations PySide6
from PySide6.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
    QPushButton, QHeaderView, QLabel, QSplitter, QSizePolicy, QTextEdit, 
    QTableView, QAbstractItemView, QMessageBox, QDialog, QLineEdit, 
    QCheckBox, QGroupBox, QGridLayout, QComboBox, QProgressBar,
    QLayout # Ajout de QLayout pour la contrainte de taille
)
from PySide6.QtCore import Qt, QThread, Signal, QModelIndex
from PySide6.QtGui import QStandardItemModel, QStandardItem, QColor, QIntValidator 

# --- CONFIGURATION GLOBALE (√Ä ADAPTER) ---
SOURCE_URL = "https://www.pndb.fr/api/explore/v2.1/catalog/exports/csv?delimiter=%3B&list_separator=%2C&quote_all=false&with_bom=true" 
# NOTE: REMPLACER LA CL√â API PAR VOTRE PROPRE CL√â LORS DE L'UTILISATION R√âELLE
API_KEY = "1ae92da78c737db274f0a03c56805a52e04ed9b5b64cd97c349f85e1" 
INPUT_DELIMITER = ";" 
OUTPUT_DELIMITER = "«Ç"
OUTPUT_FILENAME = "rapport_doublons_final.csv"

# Param√®tres de persistance
CATALOG_CACHE_DIR = "catalogs_cache"
CATALOG_FILE_EXTENSION = ".csv.gz"

# Colonne contenant l'identifiant unique du jeu de donn√©es pour l'API
UID_COLUMN_NAME = 'datasetid' 

# Les colonnes √† afficher dans le tableau du rapport
REPORT_COLUMNS = [
    'NIVEAU_DOUBLON', 'SCORE_SIMILARITE', 'CRITERE_DETECTION',
    'LIGNE_1_NUMERO', 'TITRE_LIGNE_1',
    'LIGNE_2_NUMERO', 'TITRE_LIGNE_2'
]

COLUMNS_TO_ANALYZE = [
    'default.references', 
    'default.title',      
    'default.description',
    'default.publisher',  
    'default.keyword',    
]
NUM_PROCESSES = os.cpu_count() if os.cpu_count() else 4 
BLOCK_KEY_LENGTH = 5 
MIN_LENGTH_FOR_DESC_WEIGHT = 20
# -----------------------------------


# ==============================================================================
# PARTIE 1 : LOGIQUE DE D√âDUPLICATION (Fonctionnels)
# ==============================================================================

def clean_text(text: str, is_description: bool = False) -> str:
    """ Nettoie le texte (minuscules, retrait de ponctuation, standardisation des espaces). """
    if not isinstance(text, str):
        return ""
        
    text = unicodedata.normalize('NFKC', text)
    text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'C')
    text = re.sub(r'[\u200B-\u200F\uFEFF\u202A-\u202E\u00AD\u2060-\u2064]', '', text)

    if is_description:
        text = re.sub(r'<a\s+href=.*?>.*?</a>', '', text, flags=re.IGNORECASE | re.DOTALL)
        text = re.sub(r'<br\s*/?>', '', text, flags=re.IGNORECASE)
        text = re.sub(r'lien vers les donn\w*es', '', text, flags=re.IGNORECASE)
        text = re.sub(r'fichier pr\w*sentant les donn\w*es d\w*origine et la m\w*thode de d\w*termination du budget du conservatoire du littoral', '', text, flags=re.IGNORECASE)

    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def remove_newlines(text: str) -> str:
    """ Retire les retours √† la ligne (LF et CR) d'une cha√Æne de caract√®res pour le rapport CSV. """
    if not isinstance(text, str):
        return ""
    return text.replace('\n', ' ').replace('\r', ' ').strip() 

def highlight_diff(text1: str, text2: str) -> str:
    """ Surligne les mots diff√©rents dans la LIGNE 2 par rapport √† la LIGNE 1 (en HTML). """
    
    def tokenize(text):
        text = text.lower()
        text = re.sub(r'[\W_]+', ' ', text)
        return text.split()

    words1 = tokenize(text1)
    words2 = tokenize(text2)

    set1 = set(words1)
    set2 = set(words2)

    diff_words = set2.difference(set1)
    
    current_text2 = text2
    tokens2 = re.findall(r'(\w+)', text2.lower()) 
    
    if not tokens2:
        return text2
    
    output_html = ""
    last_end = 0
    
    for word in tokens2:
        try:
            match = re.search(r'\b' + re.escape(word) + r'\b', current_text2[last_end:], re.IGNORECASE)
            
            if not match:
                match = re.search(re.escape(word), current_text2[last_end:], re.IGNORECASE)
                if not match:
                    continue

            start = match.start() + last_end
            end = match.end() + last_end
            
            original_word_slice = current_text2[start:end]
            
            output_html += current_text2[last_end:start]
            
            if word in diff_words:
                output_html += f"<span style='background-color: yellow; font-weight: bold;'>{original_word_slice}</span>"
            else:
                output_html += original_word_slice

            last_end = end
        except Exception:
            break 
            
    output_html += current_text2[last_end:]
    
    return output_html

# NOUVELLE FONCTION POUR LE CALCUL DE SIMILARIT√â TF-IDF (√âtape 2)
def calculate_tfidf_similarity(text1: str, text2: str) -> float:
    """ 
    Calcule la similarit√© cosinus TF-IDF entre deux cha√Ænes (corpus ad-hoc).
    """
    if not text1 or not text2:
        return 0.0
    
    corpus = [text1, text2]
    
    # Configuration du vectoriseur : utilise le m√™me token_pattern que le nettoyage.
    vectorizer = TfidfVectorizer(token_pattern=r'\b\w+\b') 
    try:
        tfidf_matrix = vectorizer.fit_transform(corpus)
        
        # Similarit√© Cosinus entre le document 1 (ligne 0) et le document 2 (ligne 1)
        similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0] * 100
        return float(similarity)
    except ValueError:
        # Cas o√π les documents sont trop courts ou vides apr√®s vectorisation.
        return 0.0


def compare_chunk(
    df_cleaned: pd.DataFrame, 
    indices_pairs: List[Tuple[int, int]], 
    enabled_rules: List[str],
    similarity_threshold_strong: int,
    similarity_threshold_probable: int
) -> List[Tuple[int, int, str, float]]:
    """ Fonction de travail pour le multiprocessing (d√©tection des doublons). """
    local_doubles: List[Tuple[int, int, str, float]] = []
    
    MIN_SIGNIFICANT_LENGTH = 20
    
    for i, j in indices_pairs:
        row1 = df_cleaned.iloc[i]
        row2 = df_cleaned.iloc[j]
        
        # R√àGLE : IDENTIT√â TOTALE (100%)
        if 'TOTAL' in enabled_rules:
            
            title1_clean = row1.get('default.title_CLEAN', '')
            title2_clean = row2.get('default.title_CLEAN', '')
            desc1_clean = row1.get('default.description_CLEAN', '')
            desc2_clean = row2.get('default.description_CLEAN', '')

            is_title_match = (title1_clean == title2_clean)
            is_desc_match = (desc1_clean == desc2_clean)
            is_valid_entry = (title1_clean != "" and len(desc1_clean) >= MIN_SIGNIFICANT_LENGTH)
            
            if is_title_match and is_desc_match and is_valid_entry:
                local_doubles.append((i, j, 'Titre et Description', 100.0))
                continue
        
        # R√àGLE : IDENTIT√â FORTE (> Seuil FORTE) - FuzzyWuzzy
        if 'FORTE' in enabled_rules:
            title1_clean = row1.get('default.title_CLEAN', '')
            title2_clean = row2.get('default.title_CLEAN', '')
            desc1_clean = row1.get('default.description_CLEAN', '')
            desc2_clean = row2.get('default.description_CLEAN', '')
            
            # Score 1: Titre (Ratio - plus strict)
            score_title = fuzz.ratio(title1_clean, title2_clean)

            # Score 2: Description (Token Set Ratio - plus tol√©rant √† l'ordre)
            score_desc = fuzz.token_set_ratio(desc1_clean, desc2_clean)
            
            # Calcul du score total de similarit√© : Pond√©ration 2:1 (Titre:Description) si la description est significative
            if len(desc1_clean) > MIN_LENGTH_FOR_DESC_WEIGHT and len(desc2_clean) > MIN_LENGTH_FOR_DESC_WEIGHT:
                # Pond√©ration (Titre * 2 + Description * 1) / 3
                score_total = (2 * score_title + 1 * score_desc) / 3.0
                criteria = 'Titre (Ratio) [66%] + Description (Token Set) [33%]'
            else:
                # Si la description n'est pas significative, on se base uniquement sur le titre
                score_total = score_title
                criteria = 'Titre (Ratio) Seul'

            # V√©rification du seuil fort
            if score_total >= similarity_threshold_strong:
                local_doubles.append((i, j, criteria, float(score_total)))
                continue

        # NOUVELLE R√àGLE : TF-IDF (Similarit√© Cosinus) - Analogue √† la r√®gle Forte
        if 'TFIDF' in enabled_rules:
            title1_clean = row1.get('default.title_CLEAN', '')
            title2_clean = row2.get('default.title_CLEAN', '')
            desc1_clean = row1.get('default.description_CLEAN', '')
            desc2_clean = row2.get('default.description_CLEAN', '')
            
            # Score 1: Titre (Similarit√© Cosinus TF-IDF)
            score_title_tfidf = calculate_tfidf_similarity(title1_clean, title2_clean)

            # Score 2: Description (Similarit√© Cosinus TF-IDF)
            score_desc_tfidf = calculate_tfidf_similarity(desc1_clean, desc2_clean)
            
            # D√©termination de la significativit√©
            # MIN_LENGTH_FOR_DESC_WEIGHT DOIT √äTRE DEFINI (par exemple 20)
            is_desc1_significant = len(desc1_clean) > MIN_LENGTH_FOR_DESC_WEIGHT
            is_desc2_significant = len(desc2_clean) > MIN_LENGTH_FOR_DESC_WEIGHT
            
            if is_desc1_significant and is_desc2_significant:
                # Cas 1: Les deux descriptions sont significatives. Pond√©ration normale (2:1).
                score_total_tfidf = (2 * score_title_tfidf + 1 * score_desc_tfidf) / 3.0
                criteria_tfidf = 'Titre (TF-IDF Cosine) [66%] + Description (TF-IDF Cosine) [33%]'
            else:
                # Cas 2: Au moins une description est insignifiante.
                
                # CORRECTION : V√©rification de l'asym√©trie
                if is_desc1_significant != is_desc2_significant:
                    # Cas 2A: Asym√©trie (une longue, une courte/vide). P√©nalisation FORC√âE.
                    # Le score du titre est abaiss√© par l'absence d'une description longue.
                    score_desc_penalized = 0 # Forcer le score de description √† 0
                    score_total_tfidf = (2 * score_title_tfidf + 1 * score_desc_penalized) / 3.0
                    criteria_tfidf = 'Titre (TF-IDF Cosine) Seul (Penalis√©: DESC Asym√©trie)'
                else:
                    # Cas 2B: Les deux descriptions sont insignifiantes (courtes ou vides).
                    # Se baser uniquement sur le titre est justifiable.
                    score_total_tfidf = score_title_tfidf
                    criteria_tfidf = 'Titre (TF-IDF Cosine) Seul'

            # V√©rification du seuil fort
            if score_total_tfidf >= similarity_threshold_strong:
                local_doubles.append((i, j, criteria_tfidf, float(score_total_tfidf)))
                continue

        # R√àGLE : IDENTIT√â PROBABLE (> Seuil PROBABLE)
        if 'PROBABLE' in enabled_rules:
            score_keyword = fuzz.token_set_ratio(row1.get('default.keyword_CLEAN', ''), row2.get('default.keyword_CLEAN', ''))
            if score_keyword >= similarity_threshold_probable:
                local_doubles.append((i, j, 'default.keyword (Token Set)', float(score_keyword)))
                continue
            
            
    return local_doubles

def find_duplicates_multiprocess(
    df: pd.DataFrame, 
    enabled_rules: List[str],
    similarity_threshold_strong: int,
    similarity_threshold_probable: int
) -> Tuple[pd.DataFrame, List[List[Tuple[int, int]]], int]:
    """ G√®re la pr√©paration des donn√©es et l'identification des paires pour le Worker. """
    
    # Blocage (Blocking/Tiling)
    # df doit contenir les colonnes *_CLEAN √† ce stade
    if 'default.title_CLEAN' in df.columns:
        df['BLOCK_KEY'] = df['default.title_CLEAN'].str[:BLOCK_KEY_LENGTH].fillna('')
    else:
        # Mesure de s√©curit√© si le nettoyage a √©chou√©
        df['BLOCK_KEY'] = '' 

    all_pairs: List[Tuple[int, int]] = []
    
    for _, group in df.groupby('BLOCK_KEY'):
        if len(group) < 2:
            continue
            
        indices = group.index.tolist() 
        
        for i in range(len(indices)):
            for j in range(i + 1, len(indices)):
                all_pairs.append((indices[i], indices[j]))
    
    cols_to_keep = [f'{col}_CLEAN' for col in ['default.title', 'default.description', 'default.publisher', 'default.keyword']]
    # Inclure les colonnes _CLEAN dans le DF pour le multiprocessing
    df_for_parallel = df[[c for c in cols_to_keep if c in df.columns]].copy()
        
    chunk_size = len(all_pairs) // NUM_PROCESSES
    chunks = [all_pairs[i:i + chunk_size] for i in range(0, len(all_pairs), chunk_size)]
    chunks = [c for c in chunks if c] 
    
    return df_for_parallel, chunks, len(all_pairs)

def generate_csv_report(doubles: Dict[str, List[Tuple[int, int, str, float]]], df: pd.DataFrame, filename: str) -> None:
    """ G√©n√®re un rapport de doublons dans un fichier CSV structur√©. """
    
    all_matches = []
    # Assure l'unicit√© par paire (i, j) en priorisant le niveau de doublon le plus "fort"
    unique_pairs = {} 

    # Parcourir les niveaux de force (Total > Forte > Probable) pour n'enregistrer que le meilleur score
    level_order = ['Identit√© Totale', 'Identit√© Forte', 'Identit√© Probable']
    
    for level in level_order:
        for i, j, criteria, score in doubles.get(level, []):
            pair_key = tuple(sorted((i, j)))
            
            # Si la paire n'a pas encore √©t√© enregistr√©e ou si le niveau actuel est plus fort
            if pair_key not in unique_pairs:
                unique_pairs[pair_key] = (level, i, j, criteria, score)
                
    for (i, j), (level, i_row, j_row, criteria, score) in unique_pairs.items():
            
            # Utilisation des colonnes originales pour le rapport CSV
            row1_title = remove_newlines(df.iloc[i_row].get('default.title', ''))
            row2_title = remove_newlines(df.iloc[j_row].get('default.title', ''))
            row1_ref = remove_newlines(df.iloc[i_row].get('default.references', ''))
            row2_ref = remove_newlines(df.iloc[j_row].get('default.references', ''))
            
            row1_desc = remove_newlines(df.iloc[i_row].get('default.description', ''))
            row2_desc = remove_newlines(df.iloc[j_row].get('default.description', ''))
            row1_pub = remove_newlines(df.iloc[i_row].get('default.publisher', ''))
            row2_pub = remove_newlines(df.iloc[j_row].get('default.publisher', ''))
            row1_kw = remove_newlines(df.iloc[i_row].get('default.keyword', ''))
            row2_kw = remove_newlines(df.iloc[j_row].get('default.keyword', ''))
            
            all_matches.append({
                'NIVEAU_DOUBLON': level,
                'LIGNE_1_INDEX_0': i_row,
                'LIGNE_2_INDEX_0': j_row,
                'LIGNE_1_NUMERO': i_row + 2, 
                'LIGNE_2_NUMERO': j_row + 2,
                'SCORE_SIMILARITE': f"{score:.2f}%",
                'CRITERE_DETECTION': criteria,
                'TITRE_LIGNE_1': row1_title,
                'TITRE_LIGNE_2': row2_title,
                'REFERENCE_LIGNE_1': row1_ref,
                'REFERENCE_LIGNE_2': row2_ref,
                'DESCRIPTION_LIGNE_1': row1_desc,
                'DESCRIPTION_LIGNE_2': row2_desc,
                'PUBLISHER_LIGNE_1': row1_pub,
                'PUBLISHER_LIGNE_2': row2_pub,
                'KEYWORDS_LIGNE_1': row1_kw,
                'KEYWORDS_LIGNE_2': row2_kw,
            })
            
    report_df = pd.DataFrame(all_matches).drop_duplicates(subset=['LIGNE_1_INDEX_0', 'LIGNE_2_INDEX_0'], keep='first')
    
    if not report_df.empty and 'TITRE_LIGNE_1' in report_df.columns:
        report_df = report_df.sort_values(by='TITRE_LIGNE_1', ascending=True)

    report_df.to_csv(filename, 
                     sep=OUTPUT_DELIMITER, 
                     index=False, 
                     encoding='utf-8', 
                     quoting=csv.QUOTE_ALL)
    
    return report_df.shape[0]

# ==============================================================================
# PARTIE 2 : WORKERS (Chargement, Analyse et Action API)
# ==============================================================================

class CatalogLoaderWorker(QThread):
    """ Worker pour t√©l√©charger et sauvegarder le catalogue en arri√®re-plan. """
    
    finished = Signal(bool, object, str) 
    progress = Signal(int, str) 

    def __init__(self, parent=None):
        super().__init__(parent)

    def run(self):
        """ Contient la logique bloquante du t√©l√©chargement et du traitement Pandas. """
        try:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            self.progress.emit(5, "T√©l√©chargement du catalogue (1/3)...")
            headers = {'Authorization': f'Apikey {API_KEY}'}
            response = requests.get(SOURCE_URL, headers=headers, timeout=120) 
            response.raise_for_status() 

            csv_content = io.StringIO(response.content.decode('utf-8'))
            
            self.progress.emit(50, "Lecture et pr√©traitement des donn√©es (2/3)...")
            df = pd.read_csv(csv_content, 
                             sep=INPUT_DELIMITER, 
                             dtype=str, 
                             encoding='utf-8', 
                             on_bad_lines='skip',
                             engine='python',        
                             quotechar='"',          
                             doublequote=True) 
            
            # S'assurer que la colonne UID est pr√©sente, sinon l'action de d√©publication √©chouera
            if UID_COLUMN_NAME not in df.columns:
                 print(f"ATTENTION: Colonne UID '{UID_COLUMN_NAME}' manquante. La d√©publication ne fonctionnera pas.")

            df['CSV_LINE_NUMERO'] = df.index + 2 
            df = df.set_index('CSV_LINE_NUMERO')
            
            self.progress.emit(80, "Sauvegarde locale du catalogue (3/3)...")
            Path(CATALOG_CACHE_DIR).mkdir(exist_ok=True)
            filename_key = timestamp.replace(' ', '_').replace(':', '-') 
            filename = f"catalogue_{filename_key}{CATALOG_FILE_EXTENSION}"
            save_path = Path(CATALOG_CACHE_DIR) / filename
            
            df.to_csv(save_path, sep=INPUT_DELIMITER, compression='gzip', index=True, encoding='utf-8', quoting=csv.QUOTE_ALL)
            
            self.progress.emit(100, "T√©l√©chargement termin√©.")
            self.finished.emit(True, df, f"Catalogue du {timestamp} ({len(df)} lignes)")
            
        except requests.exceptions.HTTPError as e:
            status_code = e.response.status_code if e.response is not None else 'N/A'
            msg = f"Erreur HTTP ({status_code}) lors du t√©l√©chargement. V√©rifiez la cl√© API et l'URL: {e}"
            self.progress.emit(0, "Erreur.")
            self.finished.emit(False, None, msg)
        except requests.exceptions.RequestException as e:
            msg = f"Erreur de connexion lors du t√©l√©chargement : {e}"
            self.progress.emit(0, "Erreur.")
            self.finished.emit(False, None, msg)
        except Exception as e:
            msg = f"Erreur lors du traitement des donn√©es t√©l√©charg√©es : {e}"
            self.progress.emit(0, "Erreur.")
            self.finished.emit(False, None, msg)


class DeduplicationWorker(QThread):
    """ Worker pour ex√©cuter l'analyse de d√©duplication en arri√®re-plan. """
    
    finished = Signal(bool, str) 
    progress = Signal(int, str) 

    def __init__(self, df: pd.DataFrame, settings: Dict[str, Any], parent=None):
        super().__init__(parent)
        self.df = df 
        self.settings = settings

    def run(self):
        """ Contient la logique bloquante de l'analyse de d√©duplication. """
        try:
            # df est cens√© contenir les colonnes *_CLEAN √† ce stade
            df_copy = self.df.copy() 
            for col in COLUMNS_TO_ANALYZE:
                if col not in df_copy.columns:
                    df_copy[col] = ''
            df_reset = df_copy.reset_index(drop=True)

            self.progress.emit(5, "Pr√©paration et d√©coupage des donn√©es (1/3)...")
            
            df_for_parallel, chunks, total_pairs = find_duplicates_multiprocess(
                df_reset, 
                self.settings['enabled_rules'],
                self.settings['similarity_threshold_strong'],
                self.settings['similarity_threshold_probable']
            )

            total_chunks = len(chunks)
            if total_chunks == 0:
                self.progress.emit(100, "Aucune paire √† comparer. Analyse termin√©e.")
                self.finished.emit(True, "Analyse termin√©e, 0 paires √† comparer.")
                return

            self.progress.emit(10, f"D√©marrage de l'analyse parall√®le sur {total_chunks} blocs (2/3)...")
            
            final_doubles = {'Identit√© Totale': [], 'Identit√© Forte': [], 'Identit√© Probable': []}
            
            common_args = (self.settings['enabled_rules'], self.settings['similarity_threshold_strong'], self.settings['similarity_threshold_probable'])
            
            with ProcessPoolExecutor(max_workers=NUM_PROCESSES) as executor:
                futures = [executor.submit(compare_chunk, df_for_parallel, chunk, *common_args) for chunk in chunks]
                
                for i, future in enumerate(as_completed(futures)):
                    local_doubles = future.result()
                    
                    for i_pair, j_pair, criteria, score in local_doubles:
                        # LOGIQUE DE D√âTERMINATION DU NIVEAU MISE √Ä JOUR (√âtape 6)
                        if criteria == 'Titre et Description':
                            level = 'Identit√© Totale'
                        # Les crit√®res des r√®gles FORTE (FuzzyWuzzy) et TFIDF contiennent "Titre (Ratio)" ou "TF-IDF Cosine"
                        elif 'Titre (Ratio)' in criteria or 'TF-IDF Cosine' in criteria: 
                            level = 'Identit√© Forte'
                        # Le crit√®re de la r√®gle PROBABLE contient "Token Set" (pour les mots-cl√©s)
                        elif 'Token Set' in criteria:
                            level = 'Identit√© Probable'
                        else:
                            level = 'Identit√© Probable' 
                            
                        final_doubles[level].append((i_pair, j_pair, criteria, score))
                    
                    percent = 10 + int(80 * (i + 1) / total_chunks)
                    self.progress.emit(percent, f"Analyse des doublons ({i+1}/{total_chunks} blocs trait√©s)")

            self.progress.emit(90, "G√©n√©ration du rapport CSV final (3/3)...")
            
            generate_csv_report(final_doubles, df_reset, OUTPUT_FILENAME)
            
            self.progress.emit(100, "Analyse termin√©e.")
            self.finished.emit(True, f"Analyse termin√©e avec succ√®s.")
            
        except Exception as e:
            error_msg = f"Une erreur inattendue s'est produite lors de l'analyse : {e}"
            self.progress.emit(0, "Erreur.")
            self.finished.emit(False, error_msg)


class ApiActionWorker(QThread):
    """ Worker pour ex√©cuter des actions API (comme la d√©publication) en arri√®re-plan. """
    
    # Signal: (success, message, line_num)
    finished = Signal(bool, str, int)  

    def __init__(self, datasetid: str, line_num: int, api_key: str, parent=None):
        super().__init__(parent)
        self.datasetid = datasetid
        self.line_num = line_num
        self.api_key = api_key
        self.base_url = "https://www.pndb.fr/api"

    def run(self):
        """ Ex√©cute l'op√©ration de d√©publication en deux √©tapes : obtenir l'UID, puis d√©publier. """
        try:
            # 1. Obtenir le dataset_uid (l'identifiant interne pour l'API automation)
            # Utilisation de datasetid dans l'URL de l'API EXPLORE comme fourni par l'utilisateur
            explore_url = f"{self.base_url}/explore/v2.1/catalog/datasets/{self.datasetid}?timezone=UTC&include_links=false&include_app_metas=false"
            
            response = requests.get(explore_url, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            # Le dataset_uid pour l'API automation est l'ID interne ('dataset_uid') ou parfois l'id racine.
            # CORRECTION APPLIQU√âE ICI : Utiliser 'dataset_uid' au lieu de 'id'
            dataset_uid = data.get('dataset_uid') 
            
            if not dataset_uid:
                # Si 'dataset_uid' n'est pas trouv√©, v√©rifiez la cl√© 'id' comme alternative.
                dataset_uid = data.get('id')
                
            if not dataset_uid:
                self.finished.emit(False, f"Erreur L{self.line_num}: ID automation ('dataset_uid' ou 'id') non trouv√© dans la r√©ponse pour datasetid '{self.datasetid}'.", self.line_num)
                return

            # 2. Envoyer la requ√™te de d√©publication (POST)
            unpublish_url = f"{self.base_url}/automation/v1.0/datasets/{dataset_uid}/unpublish/"
            headers = {'Authorization': f'Apikey {self.api_key}'}
            
            # L'API automation/v1.0 n√©cessite une requ√™te POST
            response = requests.post(unpublish_url, headers=headers, timeout=30)
            response.raise_for_status()
            
            # V√©rifier la r√©ponse de d√©publication (le statut 204 No Content est souvent attendu)
            if response.status_code in [200, 204]:
                msg = f"‚úÖ L{self.line_num}: D√©publication r√©ussie pour '{dataset_uid}' (datasetid: {self.datasetid})."
                self.finished.emit(True, msg, self.line_num)
            else:
                error_msg = response.text
                msg = f"‚ùå L{self.line_num}: √âchec de la d√©publication (Statut {response.status_code}). R√©ponse: {error_msg[:100]}..."
                self.finished.emit(False, msg, self.line_num)

        except requests.exceptions.RequestException as e:
            msg = f"‚ùå L{self.line_num}: Erreur r√©seau/API lors de l'op√©ration: {e}"
            self.finished.emit(False, msg, self.line_num)
        except Exception as e:
            msg = f"‚ùå L{self.line_num}: Erreur inattendue: {e}"
            self.finished.emit(False, msg, self.line_num)


# ==============================================================================
# PARTIE 3 : DIALOGUE DE CONFIGURATION (Modifi√©e pour inclure TFIDF)
# ==============================================================================

class SettingsDialog(QDialog):
    
    def __init__(self, current_settings: Dict[str, Any], parent=None):
        super().__init__(parent)
        self.setWindowTitle("‚öôÔ∏è Param√®tres de D√©duplication")
        self.current_settings = current_settings
        self.new_settings = current_settings.copy()
        
        # self.setFixedSize(400, 300) # CODE ORIGINAL REMPLAC√â
        self._setup_ui()
        # NOUVEAU: Contrainte de taille apr√®s la mise en place du layout
        self.layout().setSizeConstraint(QLayout.SetFixedSize) 
    
    def _setup_ui(self):
        main_layout = QVBoxLayout(self)
        
        rules_group = QGroupBox("R√®gles de D√©tection (Cochez pour Activer)")
        rules_layout = QVBoxLayout()
        
        self.checkboxes = {}
        # MODIFICATION : Ajout de la r√®gle 'TFIDF' (√âtape 5)
        for rule_name in ['TOTAL', 'FORTE', 'PROBABLE', 'TFIDF']: 
            cb = QCheckBox(f"R√®gle '{rule_name}'")
            if rule_name in self.current_settings['enabled_rules']:
                cb.setChecked(True)
            self.checkboxes[rule_name] = cb
            rules_layout.addWidget(cb)
            
        rules_group.setLayout(rules_layout)
        main_layout.addWidget(rules_group)
        
        threshold_group = QGroupBox("Seuils de Similarit√© (Score en %)")
        threshold_layout = QGridLayout()
        
        threshold_layout.addWidget(QLabel("Seuil 'FORTE' (Titre Ratio):"), 0, 0)
        self.strong_threshold_input = QLineEdit(str(self.current_settings['similarity_threshold_strong']))
        self.strong_threshold_input.setValidator(QIntValidator(0, 100, self))
        threshold_layout.addWidget(self.strong_threshold_input, 0, 1)
        
        threshold_layout.addWidget(QLabel("Seuil 'PROBABLE' (Token Set):"), 1, 0)
        self.probable_threshold_input = QLineEdit(str(self.current_settings['similarity_threshold_probable']))
        self.probable_threshold_input.setValidator(QIntValidator(0, 100, self))
        threshold_layout.addWidget(self.probable_threshold_input, 1, 1)
        
        threshold_group.setLayout(threshold_layout)
        main_layout.addWidget(threshold_group)
        
        button_layout = QHBoxLayout()
        ok_button = QPushButton("Appliquer")
        ok_button.clicked.connect(self.accept)
        cancel_button = QPushButton("Annuler")
        cancel_button.clicked.connect(self.reject)
        
        button_layout.addStretch()
        button_layout.addWidget(ok_button)
        button_layout.addWidget(cancel_button)
        
        main_layout.addLayout(button_layout)
        
    def get_settings(self) -> Dict[str, Any]:
        """ Retourne les param√®tres valid√©s. """
        
        new_enabled_rules = []
        # La boucle parcourt d√©sormais 'TOTAL', 'FORTE', 'PROBABLE', 'TFIDF'
        for rule_name, checkbox in self.checkboxes.items(): 
            if checkbox.isChecked():
                new_enabled_rules.append(rule_name)
        
        try:
            strong_t = int(self.strong_threshold_input.text())
        except ValueError:
            strong_t = self.current_settings['similarity_threshold_strong'] 
            
        try:
            probable_t = int(self.probable_threshold_input.text())
        except ValueError:
            probable_t = self.current_settings['similarity_threshold_probable']

        self.new_settings['enabled_rules'] = new_enabled_rules
        self.new_settings['similarity_threshold_strong'] = max(0, min(100, strong_t))
        self.new_settings['similarity_threshold_probable'] = max(0, min(100, probable_t))
        
        return self.new_settings


# ==============================================================================
# PARTIE 4 : INTERFACE GRAPHIQUE PRINCIPALE
# ==============================================================================

class MainWindow(QMainWindow):
    """ Fen√™tre principale de l'application de Data Quality. """
    
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Outil de Data Quality - D√©duplication")
        self.setGeometry(100, 100, 1400, 800)
        
        self.settings: Dict[str, Any] = {
            # MODIFICATION : Ajout de 'TFIDF' dans les r√®gles activ√©es par d√©faut (√âtape 4)
            'enabled_rules': ['TOTAL', 'FORTE', 'PROBABLE', 'TFIDF'], 
            'similarity_threshold_strong': 99,
            'similarity_threshold_probable': 80
        }
        
        self.catalogs: Dict[str, pd.DataFrame] = {} 
        self.current_catalog_key: Optional[str] = None
        self.report_df: pd.DataFrame = pd.DataFrame()
        
        self.deduplication_worker = None 
        self.catalog_loader_worker = None 
        self.api_action_worker = None 
        
        # Variables pour stocker les IDs des lignes actuellement affich√©es
        self.current_datasetid_1: Optional[str] = None
        self.current_datasetid_2: Optional[str] = None
        self.current_line_num_1: Optional[int] = None
        self.current_line_num_2: Optional[int] = None

        self._setup_ui()
        
        self._load_cached_catalogs()
        self._load_report_on_startup() 
        
    
    # --- NOUVELLE M√âTHODE : S'assurer que les colonnes *_CLEAN existent ---
    def _ensure_cleaned_columns_exist(self, df: pd.DataFrame) -> None:
        """ 
        G√©n√®re les colonnes de donn√©es nettoy√©es (*_CLEAN) si elles sont manquantes.
        Ceci est essentiel pour que la vue de comparaison fonctionne, m√™me si l'analyse
        de d√©duplication n'a pas √©t√© lanc√©e.
        """
        
        # Colonnes pour nettoyage standard
        for col in ['default.title', 'default.publisher', 'default.keyword']:
            clean_col = f'{col}_CLEAN'
            if col in df.columns and clean_col not in df.columns:
                df[clean_col] = df[col].apply(clean_text)
                
        # Colonne pour nettoyage sp√©cifique (description)
        desc_col = 'default.description'
        clean_desc_col = 'default.description_CLEAN'
        if desc_col in df.columns and clean_desc_col not in df.columns:
            df[clean_desc_col] = df[desc_col].apply(lambda x: clean_text(x, is_description=True))

    def _load_cached_catalogs(self):
        cache_path = Path(CATALOG_CACHE_DIR)
        if not cache_path.exists():
            return
            
        loaded_count = 0
        catalog_files = sorted(list(cache_path.glob(f"catalogue_*{CATALOG_FILE_EXTENSION}")), reverse=True)
        
        self.catalog_selector.clear()
        
        for file_path in catalog_files:
            try:
                base_name = file_path.stem.replace('catalogue_', '')
                match = re.search(r'(\d{4}-\d{2}-\d{2})_(\d{2})-(\d{2})-(\d{2})', base_name)
                
                if match:
                    date_part = match.group(1)
                    time_part = f"{match.group(2)}:{match.group(3)}:{match.group(4)}"
                    key = f"{date_part} {time_part}"
                else:
                    key = file_path.stem 
                
                df = pd.read_csv(
                    file_path, 
                    sep=INPUT_DELIMITER, 
                    compression='gzip',
                    dtype=str, 
                    encoding='utf-8',
                    index_col='CSV_LINE_NUMERO', 
                    engine='python' 
                )
                
                # --- CORRECTIF : Assurer les colonnes de nettoyage au chargement du cache ---
                self._ensure_cleaned_columns_exist(df)
                
                self.catalogs[key] = df
                self.catalog_selector.addItem(key)
                loaded_count += 1
                
            except Exception:
                pass
                
        if loaded_count > 0:
            self.catalog_selector.setCurrentIndex(0) 
            self.catalog_selector.setEnabled(True)
            self.run_button.setEnabled(True)
            self.current_catalog_key = self.catalog_selector.currentText()
            self.status_label.setText(f"Statut: ‚úÖ {loaded_count} catalogues pr√©c√©demment charg√©s trouv√©s. Actif: '{self.current_catalog_key}'.")
        else:
            self.catalog_selector.setEnabled(False)
            self.run_button.setEnabled(False)


    def get_active_dataframe(self) -> pd.DataFrame:
        """ Retourne le DataFrame actif ou un DataFrame vide. """
        if self.current_catalog_key and self.current_catalog_key in self.catalogs:
            return self.catalogs[self.current_catalog_key]
        return pd.DataFrame()
        
    def open_settings_dialog(self):
        dialog = SettingsDialog(self.settings, self)
        
        if dialog.exec():
            new_settings = dialog.get_settings()
            self.settings = new_settings
            self.status_label.setText("Statut: Param√®tres mis √† jour. (Pr√™t √† relancer l'analyse)")
            
    def update_progress_bar(self, value: int, text: str):
        self.progress_bar.setValue(value)
        self.progress_bar.setFormat(f"{text} %p%")
        self.progress_bar.setVisible(value > 0 and value < 100)
            
    def _setup_ui(self):
        """ Configuration de l'interface utilisateur. """
        main_widget = QWidget()
        main_layout = QVBoxLayout(main_widget)

        # 1. Contr√¥les (Haut)
        control_layout = QHBoxLayout()
        
        self.download_button = QPushButton("‚¨áÔ∏è T√©l√©charger le Catalogue")
        self.download_button.clicked.connect(self.start_catalog_download)
        
        self.catalog_selector = QComboBox()
        self.catalog_selector.setMinimumWidth(300)
        self.catalog_selector.setToolTip("S√©lectionnez la version du catalogue √† analyser (y compris les versions persistantes).")
        self.catalog_selector.currentIndexChanged.connect(self.update_active_catalog)
        self.catalog_selector.setEnabled(False) 
        
        self.run_button = QPushButton("üöÄ Lancer l'analyse de d√©duplication")
        self.run_button.clicked.connect(self.start_deduplication_analysis)
        self.run_button.setEnabled(False) 
        
        self.settings_button = QPushButton("‚öôÔ∏è Param√®tres")
        self.settings_button.clicked.connect(self.open_settings_dialog)
        
        self.status_label = QLabel("Statut: Pr√™t. Aucun catalogue charg√©.")
        
        self.progress_bar = QProgressBar() 
        self.progress_bar.setRange(0, 100)
        self.progress_bar.setValue(0)
        self.progress_bar.setTextVisible(True)
        self.progress_bar.setVisible(False)
        
        control_layout.addWidget(self.download_button)
        control_layout.addWidget(self.catalog_selector)
        control_layout.addWidget(self.run_button)
        control_layout.addWidget(self.settings_button)
        control_layout.addStretch()
        control_layout.addWidget(self.status_label)
        control_layout.addWidget(self.progress_bar) 
        main_layout.addLayout(control_layout)
        
        # 2. S√©parateur (Milieu) : Rapport et Comparaison
        splitter = QSplitter(Qt.Orientation.Vertical)
        
        # A. Vue du Rapport (Tableau)
        report_group = QWidget()
        report_layout = QVBoxLayout(report_group)
        report_layout.addWidget(QLabel("Rapport de doublons trouv√©s:"))
        
        self.report_table = QTableView()
        self.report_table.setSelectionBehavior(QAbstractItemView.SelectionBehavior.SelectRows)
        self.report_table.setSelectionMode(QAbstractItemView.SelectionMode.SingleSelection)
        
        self.report_model = QStandardItemModel()
        self.report_table.setModel(self.report_model)
        
        selection_model = self.report_table.selectionModel()
        if selection_model:
            selection_model.currentChanged.connect(self.show_comparison_view)
        
        # FIX DE HAUTEUR : Hauteur minimale et maximale (d√©sactiv√© pour compatibilit√© multiplateforme DPI)
        MIN_HEIGHT = 150 # Estimer une hauteur raisonnable en pixels
        # ROW_HEIGHT_ESTIMATE = 25 
        # HEADER_HEIGHT_ESTIMATE = 30
        
        # MIN_HEIGHT = (ROW_HEIGHT_ESTIMATE * 5) + HEADER_HEIGHT_ESTIMATE # CODE ORIGINAL REMPLAC√â
        self.report_table.setMinimumHeight(MIN_HEIGHT)
        
        # MAX_HEIGHT = (ROW_HEIGHT_ESTIMATE * 15) + HEADER_HEIGHT_ESTIMATE # CODE ORIGINAL REMPLAC√â
        # self.report_table.setMaximumHeight(MAX_HEIGHT) # CODE ORIGINAL REMPLAC√â 
        
        report_layout.addWidget(self.report_table)
        splitter.addWidget(report_group)
        
        # B. Vue de Comparaison (Bas)
        comparison_group = QWidget()
        comparison_layout = QVBoxLayout(comparison_group)
        comparison_layout.setContentsMargins(0, 0, 0, 0)

        # --- Zone pour les boutons et le titre de comparaison ---
        header_widget = QWidget()
        header_layout = QGridLayout(header_widget)
        header_layout.setContentsMargins(5, 5, 5, 5) 
        header_layout.setSpacing(5)
        
        self.comparison_title_label = QLabel("Vue de Comparaison (Textes Nettoy√©s):")
        self.comparison_title_label.setStyleSheet("font-weight: bold;")
        # Ajout du titre sur toute la largeur (colonnes 0, 1, 2)
        header_layout.addWidget(self.comparison_title_label, 0, 0, 1, 3) 

        # Boutons de d√©publication
        self.unpublish_btn_1 = QPushButton("D√©publier LIGNE 1")
        self.unpublish_btn_2 = QPushButton("D√©publier LIGNE 2")
        self.unpublish_btn_1.setToolTip("D√©publie le jeu de donn√©es correspondant √† la LIGNE 1 via l'API Automation PNDB.")
        self.unpublish_btn_2.setToolTip("D√©publie le jeu de donn√©es correspondant √† la LIGNE 2 via l'API Automation PNDB.")
        self.unpublish_btn_1.setEnabled(False) 
        self.unpublish_btn_2.setEnabled(False) 
        
        # LIGNE 1: Colonne 0, Alignement √† gauche (coll√© √† gauche)
        header_layout.addWidget(self.unpublish_btn_1, 1, 0, Qt.AlignLeft)
        
        # √âTIREMENT: Colonne 1, force le bouton 2 √† droite
        header_layout.setColumnStretch(1, 1) 
        
        # LIGNE 2: Colonne 2, Alignement √† droite (coll√© √† droite)
        header_layout.addWidget(self.unpublish_btn_2, 1, 2, Qt.AlignRight) 
        
        comparison_layout.addWidget(header_widget)
        
        self.comparison_text = QTextEdit()
        self.comparison_text.setReadOnly(True)
        self.comparison_text.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Expanding)
        
        comparison_layout.addWidget(self.comparison_text)
        splitter.addWidget(comparison_group)
        
        # Initialise le splitter avec une taille permettant de voir les deux blocs
        # splitter.setSizes([MIN_HEIGHT * 2, 300]) # CODE ORIGINAL REMPLAC√â
        splitter.setSizes([300, 500]) # NOUVEAU: Initialisation plus g√©n√©rique 
        main_layout.addWidget(splitter)

        self.setCentralWidget(main_widget)
        
        # Connexion des nouveaux boutons
        self.unpublish_btn_1.clicked.connect(lambda: self.unpublish_button_clicked(1))
        self.unpublish_btn_2.clicked.connect(lambda: self.unpublish_button_clicked(2))
        
    def _load_report_on_startup(self):
        if os.path.exists(OUTPUT_FILENAME):
            self.load_report_into_table(OUTPUT_FILENAME)
        else:
            if not self.catalogs:
                self.status_label.setText("Statut: Pr√™t. Aucun catalogue charg√©. Lancez un t√©l√©chargement.")
            
    def start_catalog_download(self):
        if self.catalog_loader_worker and self.catalog_loader_worker.isRunning():
            QMessageBox.warning(self, "T√©l√©chargement en cours", "Un t√©l√©chargement est d√©j√† en cours. Veuillez patienter.")
            return

        self.catalog_loader_worker = CatalogLoaderWorker()
        self.catalog_loader_worker.finished.connect(self.catalog_loaded_result)
        self.catalog_loader_worker.progress.connect(self.update_progress_bar) 
        
        self.status_label.setText("Statut: ‚¨áÔ∏è T√©l√©chargement du catalogue depuis l'API...")
        
        self.download_button.setEnabled(False)
        self.run_button.setEnabled(False)
        self.settings_button.setEnabled(False) 
        self.catalog_selector.setEnabled(False) 
        
        self.catalog_loader_worker.start() 

    def catalog_loaded_result(self, success: bool, result: Optional[pd.DataFrame], message: str):
        self.download_button.setEnabled(True)
        self.settings_button.setEnabled(True) 
        self.update_progress_bar(0, "") 

        if success and result is not None:
            match = re.search(r'du (\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', message)
            new_key = match.group(1) if match else message.split('(')[0].strip()
            
            # --- CORRECTIF : Assurer les colonnes de nettoyage apr√®s un nouveau t√©l√©chargement ---
            self._ensure_cleaned_columns_exist(result)
            
            self.catalogs[new_key] = result
            
            self._load_cached_catalogs()
            
            self.catalog_selector.setEnabled(True)
            self.run_button.setEnabled(True)
            self.status_label.setText(f"Statut: ‚úÖ {message}. Catalogue actif: '{new_key}'. (Sauvegard√© localement)")
            
        else:
            self.status_label.setText(f"Statut: ‚ùå √âchec du t√©l√©chargement - {message}")
            QMessageBox.critical(self, "Erreur de T√©l√©chargement", message)
            
            if not self.catalogs:
                self.run_button.setEnabled(False)
                self.catalog_selector.setEnabled(False)
            else:
                self.run_button.setEnabled(True)
                self.catalog_selector.setEnabled(True)
            
    def update_active_catalog(self):
        new_key = self.catalog_selector.currentText()
        if new_key and new_key in self.catalogs:
            self.current_catalog_key = new_key
            
            # --- CORRECTIF : S'assurer que le DF actif a les colonnes nettoy√©es apr√®s un changement ---
            active_df = self.get_active_dataframe()
            if not active_df.empty:
                self._ensure_cleaned_columns_exist(active_df)
            
            self.status_label.setText(f"Statut: Catalogue actif: '{new_key}'. Pr√™t.")
            self.load_report_into_table(OUTPUT_FILENAME) 
            self.run_button.setEnabled(True)
        else:
            self.current_catalog_key = None
            self.report_model.clear()
            self.status_label.setText("Statut: Veuillez t√©l√©charger ou s√©lectionner un catalogue.")
            self.run_button.setEnabled(False)

    def load_report_into_table(self, report_filename: str):
        active_df = self.get_active_dataframe()
        total_lines = len(active_df) if not active_df.empty else 0
        
        self.report_model.clear()
        
        try:
            self.report_df = pd.read_csv(
                report_filename, 
                sep=OUTPUT_DELIMITER, 
                dtype=str, 
                encoding='utf-8',
                quotechar='"',
                engine='python' 
            )
            
            display_df = self.report_df[REPORT_COLUMNS]

            self.report_model.setHorizontalHeaderLabels(display_df.columns.tolist())
            
            for index, row in display_df.iterrows():
                items = []
                for item in row:
                    std_item = QStandardItem(str(item))
                    
                    if row['NIVEAU_DOUBLON'] == 'Identit√© Totale':
                        std_item.setBackground(QColor(255, 192, 192))
                    elif row['NIVEAU_DOUBLON'] == 'Identit√© Forte':
                        std_item.setBackground(QColor(255, 255, 192))
                    
                    items.append(std_item)
                self.report_model.appendRow(items)

            self.report_table.horizontalHeader().setSectionResizeMode(QHeaderView.ResizeMode.ResizeToContents)
            
            if not self.report_df.empty and not active_df.empty:
                lignes_doublons_uniques = pd.concat([
                    self.report_df['LIGNE_1_NUMERO'].astype(str), 
                    self.report_df['LIGNE_2_NUMERO'].astype(str)
                ]).nunique()
                
                self.status_label.setText(f"Statut: Catalogue actif: '{self.current_catalog_key}'. Rapport charg√©. {len(self.report_df)} paires trouv√©es. "
                                        f"**Lignes uniques impliqu√©es : {lignes_doublons_uniques} / {total_lines}**.")
            elif not active_df.empty:
                self.status_label.setText(f"Statut: Catalogue actif: '{self.current_catalog_key}'. 0 paires trouv√©es dans le rapport.")

        except Exception:
            if not active_df.empty:
                 self.status_label.setText(f"Statut: Catalogue actif: '{self.current_catalog_key}'. Erreur lors du chargement du rapport. Lancez l'analyse pour le g√©n√©rer.")
            else:
                 self.status_label.setText("Statut: Erreur lors du chargement du rapport. Aucun catalogue actif.")


    def start_deduplication_analysis(self):
        df_active = self.get_active_dataframe()
        
        if df_active.empty:
            QMessageBox.warning(self, "Erreur", "Veuillez d'abord t√©l√©charger ou s√©lectionner une version du catalogue.")
            return

        if not self.settings['enabled_rules']:
            QMessageBox.warning(self, "Configuration Invalide", "Au moins une r√®gle de d√©tection doit √™tre s√©lectionn√©e dans les param√®tres.")
            return

        # Le nettoyage des donn√©es (cr√©ation des colonnes *_CLEAN) est d√©sormais g√©r√©
        # lors du chargement ou de la s√©lection du catalogue.

        if self.deduplication_worker and self.deduplication_worker.isRunning():
            QMessageBox.warning(self, "Analyse en cours", "L'analyse est d√©j√† en cours. Veuillez patienter.")
            return
        
        self.deduplication_worker = DeduplicationWorker(df_active, self.settings)
        self.deduplication_worker.finished.connect(self.analysis_finished)
        self.deduplication_worker.progress.connect(self.update_progress_bar) 

        self.status_label.setText(f"Statut: ‚è≥ Analyse en cours sur catalogue '{self.current_catalog_key}'...")
        self.run_button.setEnabled(False)
        self.settings_button.setEnabled(False) 
        self.download_button.setEnabled(False)
        self.catalog_selector.setEnabled(False)
        self.comparison_text.setText("")
        self.deduplication_worker.start()

    def analysis_finished(self, success: bool, message: str):
        self.run_button.setEnabled(True)
        self.settings_button.setEnabled(True) 
        self.download_button.setEnabled(True)
        self.catalog_selector.setEnabled(True)
        self.update_progress_bar(0, "") 
        
        if success:
            self.load_report_into_table(OUTPUT_FILENAME)
            
            df_active = self.get_active_dataframe()
            if not self.report_df.empty and not df_active.empty:
                lignes_doublons_uniques = pd.concat([
                    self.report_df['LIGNE_1_NUMERO'].astype(str), 
                    self.report_df['LIGNE_2_NUMERO'].astype(str)
                ]).nunique()
                total_lines = len(df_active)
                
                info_msg = (
                    f"Analyse termin√©e avec succ√®s. {len(self.report_df)} paires de doublons uniques trouv√©es.<br><br>"
                    f"**Lignes uniques du catalogue '{self.current_catalog_key}' impliqu√©es : {lignes_doublons_uniques} / {total_lines}**"
                )
            else:
                info_msg = message

            QMessageBox.information(self, "Analyse termin√©e", info_msg)
        else:
            self.status_label.setText(f"Statut: ‚ùå √âchec - {message}")
            QMessageBox.critical(self, "Erreur d'analyse", message)

    def unpublish_button_clicked(self, line_index: int):
        """ Slot appel√© lorsque l'un des boutons de d√©publication est cliqu√©. """
        if line_index == 1:
            datasetid = self.current_datasetid_1
            line_num = self.current_line_num_1
        elif line_index == 2:
            datasetid = self.current_datasetid_2
            line_num = self.current_line_num_2
        else:
            return

        self.unpublish_dataset(datasetid, line_num)

    def unpublish_dataset(self, datasetid: Optional[str], line_num: Optional[int]):
        """ Lance l'op√©ration de d√©publication via le worker API. """
        if not datasetid or datasetid == 'N/A' or line_num is None:
            QMessageBox.warning(self, "Erreur UID", f"Ligne {line_num}: L'identifiant de jeu de donn√©es (datasetid) est manquant. (V√©rifiez la pr√©sence de la colonne '{UID_COLUMN_NAME}' dans le catalogue)")
            return

        if self.api_action_worker and self.api_action_worker.isRunning():
            QMessageBox.warning(self, "Op√©ration en cours", "Une op√©ration de d√©publication est d√©j√† en cours. Veuillez patienter.")
            return

        # Confirmation par l'utilisateur
        reply = QMessageBox.question(self, 'Confirmation de D√©publication',
            f"√ätes-vous s√ªr de vouloir **D√âPUBLIER** la ligne {line_num} (datasetid: {datasetid}) ?\nCeci est une action potentiellement IRREVERSIBLE.",
            QMessageBox.Yes | QMessageBox.No, QMessageBox.No)

        if reply == QMessageBox.Yes:
            self.status_label.setText(f"Statut: ‚è≥ D√©publication en cours pour la ligne {line_num}...")
            
            self.api_action_worker = ApiActionWorker(datasetid, line_num, API_KEY)
            self.api_action_worker.finished.connect(self.handle_unpublish_result)
            
            # On ne peut pas facilement d√©sactiver les boutons ici, mais on se fie au contr√¥le du worker
            # et on d√©sactive les boutons de contr√¥le principaux pour ne pas lancer d'autre analyse
            self.run_button.setEnabled(False)
            self.download_button.setEnabled(False)
            self.api_action_worker.start()

    def handle_unpublish_result(self, success: bool, message: str, line_num: int):
        """ G√®re le r√©sultat de l'op√©ration de d√©publication. """
        
        self.run_button.setEnabled(True)
        self.download_button.setEnabled(True)
        self.status_label.setText(f"Statut: {message}")

        if success:
            QMessageBox.information(self, "D√©publication R√©ussie", message)
        else:
            QMessageBox.critical(self, "Erreur de D√©publication", message)

    def show_comparison_view(self, index: QModelIndex, previous_index: QModelIndex = None):
        """ Affiche la vue de comparaison pour la ligne s√©lectionn√©e/focus. """
        
        df_active = self.get_active_dataframe()

        if not index.isValid():
            self.comparison_text.setText("S√©lectionnez une ligne dans le rapport pour afficher la comparaison.")
            return

        if self.report_df.empty or df_active.empty:
            self.comparison_text.setText("Impossible de comparer : Le rapport ou le catalogue actif n'est pas charg√©.")
            return

        report_row_index = index.row()
        selected_report_row = self.report_df.iloc[report_row_index]
        
        line1_num = int(selected_report_row['LIGNE_1_NUMERO'])
        line2_num = int(selected_report_row['LIGNE_2_NUMERO'])
        
        try:
            data1 = df_active.loc[line1_num]
            data2 = df_active.loc[line2_num]

            # --- R√©cup√©ration et stockage des Dataset IDs et Line Numbers ---
            # Utilisation de la constante UID_COLUMN_NAME='datasetid'
            line1_datasetid = str(data1.get(UID_COLUMN_NAME, 'N/A'))
            line2_datasetid = str(data2.get(UID_COLUMN_NAME, 'N/A'))
            
            self.current_datasetid_1 = line1_datasetid
            self.current_datasetid_2 = line2_datasetid
            self.current_line_num_1 = line1_num
            self.current_line_num_2 = line2_num
            
            # Mise √† jour des libell√©s de bouton
            self.unpublish_btn_1.setText(f"D√©publier LIGNE 1 ({line1_num})")
            self.unpublish_btn_2.setText(f"D√©publier LIGNE 2 ({line2_num})")
            
            # Activation/D√©sactivation des boutons
            self.unpublish_btn_1.setEnabled(line1_datasetid != 'N/A')
            self.unpublish_btn_2.setEnabled(line2_datasetid != 'N/A')

            comparison_output = []
            
            self.comparison_title_label.setText(f"Vue de Comparaison (Textes Nettoy√©s): Paire {report_row_index + 1} (Catalogue: {self.current_catalog_key})")
            
            comparison_output.append(f"<h3 style='color: #007bff;'>Paire de Doublons: Ligne {line1_num} vs Ligne {line2_num}</h3>")
            comparison_output.append(f"<p><b>Niveau de Doublon:</b> <span style='color: {'red' if selected_report_row['NIVEAU_DOUBLON'] == 'Identit√© Totale' else 'orange'};'>{selected_report_row['NIVEAU_DOUBLON']}</span> | <b>Crit√®re:</b> {selected_report_row['CRITERE_DETECTION']} | <b>Score:</b> {selected_report_row['SCORE_SIMILARITE']}</p>")
            comparison_output.append(f"<p><b>Dataset ID 1 (pour API):</b> <span style='color: {'green' if line1_datasetid != 'N/A' else 'red'};'>{line1_datasetid}</span></p>")
            comparison_output.append(f"<p><b>Dataset ID 2 (pour API):</b> <span style='color: {'green' if line2_datasetid != 'N/A' else 'red'};'>{line2_datasetid}</span></p>")
            comparison_output.append("<hr>")

            comparison_output.append("<table style='width:100%; border-collapse: collapse;'>")
            comparison_output.append("<thead><tr style='background-color: #f0f0f0;'>")
            
            # Largeur relative : 25% pour Champ, 37.5% pour Ligne 1 et Ligne 2
            comparison_output.append("<th style='width: 25%; text-align: left; padding: 5px; border: 1px solid #ccc;'>Champ</th>")
            comparison_output.append(f"<th style='width: 37.5%; text-align: left; padding: 5px; border: 1px solid #ccc; color: #28a745;'>LIGNE 1 ({line1_num})</th>")
            comparison_output.append(f"<th style='width: 37.5%; text-align: left; padding: 5px; border: 1px solid #ccc; color: #dc3545;'>LIGNE 2 ({line2_num})</th>") 
            comparison_output.append("</tr></thead><tbody>")
            
            comparison_fields = [
                ('default.title', "Titre", True),        
                ('default.description', "Description", True), 
                ('default.publisher', "√âditeur", True),  
                ('default.keyword', "Mots-cl√©s", True), 
                ('default.references', "R√©f√©rence", False), 
            ]
            
            # Styles des cellules <td> (visuels seulement)
            style_content_td = "border: 1px solid #eee; padding: 5px;"
            style_col_1 = f"width: 37.5%; color: #28a745; {style_content_td}"
            style_col_2 = f"width: 37.5%; color: #dc3545; {style_content_td}"
            
            # NOUVEAU STYLE pour forcer le saut de ligne √† l'int√©rieur du <pre>
            # white-space: pre-wrap; permet de pr√©server les sauts de ligne existants tout en wrappant.
            # overflow-wrap: break-word; et word-break: break-all; forcent le wrapping des cha√Ænes longues.
            style_pre_content = "margin: 0; white-space: pre-wrap; overflow-wrap: break-word; word-break: break-all;"

            for field_name, display_name, use_clean in comparison_fields:
                
                if use_clean:
                    col_name = f'{field_name}_CLEAN' 
                else:
                    col_name = field_name
                    
                val1 = str(data1.get(col_name, 'N/A'))
                val2 = str(data2.get(col_name, 'N/A'))
                
                val2_highlighted = highlight_diff(val1, val2)

                comparison_output.append("<tr>")
                comparison_output.append(f"<td style='border: 1px solid #eee; padding: 5px; font-weight: bold;'>{display_name}</td>")
                # Application du NOUVEAU STYLE au <pre> pour forcer le wrapping des mots longs
                comparison_output.append(f"<td style='{style_col_1}'><pre style='{style_pre_content}'>{val1}</pre></td>") 
                # Application du NOUVEAU STYLE au <pre> pour forcer le wrapping des mots longs
                comparison_output.append(f"<td style='{style_col_2}'><pre style='{style_pre_content}'>{val2_highlighted}</pre></td>") 
                comparison_output.append("</tr>")

            comparison_output.append("</tbody></table>")
            
            self.comparison_text.setHtml("".join(comparison_output))

        except KeyError:
             self.comparison_text.setText(f"Erreur: Impossible de trouver les lignes {line1_num} ou {line2_num} dans le catalogue actif. Veuillez relancer l'analyse.")
        except Exception as e:
            self.comparison_text.setText(f"Erreur inattendue lors de la comparaison : {e}")


# ==============================================================================
# EX√âCUTION DE L'APPLICATION
# ==============================================================================

if __name__ == "__main__":
    # Correction: Ajout de QLayout √† la liste des imports PySide6 au d√©but du fichier
    if 'fuzzywuzzy' not in sys.modules or 'pandas' not in sys.modules or 'PySide6' not in sys.modules or 'requests' not in sys.modules:
        print("----------------------------------------------------------------------")
        print("Veuillez installer les librairies requises :")
        print("pip install pandas pyside6 fuzzywuzzy python-Levenshtein requests")
        print("----------------------------------------------------------------------")
    
    # Rappel : N√©cessite l'installation de scikit-learn
    if 'sklearn.feature_extraction.text' not in sys.modules:
        print("----------------------------------------------------------------------")
        print("Veuillez installer la librairie scikit-learn pour la r√®gle TFIDF :")
        print("pip install scikit-learn")
        print("----------------------------------------------------------------------")
        
    app = QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec())